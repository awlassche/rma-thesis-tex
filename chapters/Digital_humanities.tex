\chapter{Digital humanities}
This chapter focuses on one of the two main disciplines my thesis relates to: the digital humanities. I will start by giving an overview of the discipline, examining how the field has rapidly grown in the last decades. I will continue by discussing the critiques this relatively new field has had to endure, by focusing in particular on the sub-field of computational literary studies. I will end this chapter with investigating the methods that can be used to draw topics from a corpus.

\section{Computation and culture}
As already mentioned in the Introduction of this thesis, numbers and data are essential for a quantitative study. If we want to use numbers, there is one crucial quality we need, and that is good counting. And if there is anything that can perform calculations better than any human being, it is the computer. For decades, computation seemed to only belong to the field of \enquote{hard sciences}, where physics, chemistry and biology were seen as scientific fields in which objectivity, methodological rigor and exactitude take the lead: an environment in which the computer naturally resides. This contrasted with the so-called \enquote{soft sciences}, to which fields as the social sciences and the humanities belong and where methodological rigor is lacking. However, at some point it became \enquote{necessary, in the sense of unavoidable, to use computation to study culture}, Andrew Piper notices in his article \enquote{There Will Be Numbers}.\autocite[1]{piper_there_2016} Several possible explanations Piper gives for this development (a certain polemic, new kinds of data, the rise of analytical techniques, internet and social media, the critical mass), but I would say that first and foremost the ongoing large-scale process of text digitization gave rise to the introduction of computers in the humanities. The field of \textit{digital humanities} was born, out of merging two very different fields: \textit{computation} and \textit{culture}.\autocite[2]{piper_there_2016} What the value of computation for the humanities is, is well explained by Piper:
\begin{quote}
	Computation forces us to rethink our current disciplinary practices in the humanities from the ground up. What counts as evidence? What is the relationship between theory and practice? How do we account for the technological mediations of our critique? But culture too impinges upon computation. It challenges the universalism and the neutrality implicit in many computational applications. It reminds us that knowledge is always situated, somewhere, at some time, by someone. Putting culture into computation cautions us to remember where we are when we think we know something.\autocite[2]{piper_there_2016}
\end{quote}

\noindent Regarding the field of literary studies, the introduction of digital methods caused a \enquote{computational turn}, resulting in the birth of the subfield \textit{computational literary studies}. In that context, Italian literary scholar Franco Moretti coined the term \enquote{distant reading} at the very beginning of the twenty-first century, which he accompanied with a moral claim to readers and scholars. His idea was that we only read and research 0.5 percent of all published novels, and by doing so, we send the other 99.5 percent to the so-called \enquote{slaughterhouse of literature}.\autocite{moretti_slaughterhouse_2000} By \enquote{doing} distant reading, we would be able to \enquote{look beyond the canon}\autocite[57]{moretti_conjectures_2000} and thus to research the other 99.5 percent. This contrasts with the method of close reading, which depends in Moretti's eyes on an extremely small canon (the 0.5 percent), and is therefore not able to investigate all literature of the world. Distant reading presents us with the opportunity \enquote{to focus on units that are much smaller or much larger than the text}, Moretti explains.\autocite[57]{moretti_conjectures_2000} A unit can be a word, a theme, a genre, a style, et cetera. This new method of performing literary research was presented by Moretti as an offer one could not possibly refuse: \enquote{If you did not do distant reading, you were presumably ignoring the cries of thousands of volumes forgotten in \enquote*{the slaughterhouse of literature}}, Ted Underwood ironically states in his latest work \textit{Distant Horizons}.\autocite[xx]{underwood_distant_2019}

Although making this urgent call to his readers, Moretti himself included several chapters in his book \textit{Distant Reading} devoted to canonical works that have never even been close to the slaughterhouse of literature, such as Shakespeare's canonical work \textit{Hamlet}.\autocite{moretti_distant_2013} This one of the many critiques he received during the years. Others argued that, despite his approach to study world literature as a whole, Moretti is guilty of an \enquote{unavowed imperialism of English} \autocite{arac_anglo-globalism_2002} and by focusing on the Anglophones, Moretti is reproducing the same cultural hierarchy he is trying to describe.\autocite{serlen_distant_2010} However, the point of distant reading is, in Underwood's words, \enquote{not to recover a complete archive of all published works but to understand the contrast between samples drawn from different periods or social contexts.}\autocite[xx]{underwood_distant_2019} In the case of the present study, the goal is not to rescue a complete corpus of all published songs in the history of Dutch song culture from the slaughterhouse. First of all, a large part of the legacy of Dutch song culture is already \enquote{rescued}, and furthermore, the fact that there have been songs which we do not know (yet) and are therefore not included in our corpus, does not nullify the validation to research the corpus that is at hand. As Underwood states, the availability of the corpus gives the opportunity to research and understand how songs from different periods relate to each other.

The last has been done not only by Underwood, but also by Piper, Matthew Jockers and many more literary scholars. Crucial to this kind of research is the digital availability of big corpora containing thousands of novels, news articles, songs, et cetera. The Dutch Song Database is just a tiny example of the process of digitization that has taken place since the last decades of the previous century.\footnote{For example, Google Books contains over 25 million books nowadays. For comparison: the Short Title Catalogue Netherlands (STCN) contains metadata of 210.000 Dutch texts, published between 1540 and 1800.}

\section{Debate}
Two decades after postulating \enquote{distant reading}, the polemics that originally accompanied the term have been replaced by a broader debate on the importance and relevance of the field of computational literary studies within the digital humanities. The most recent contribution to this discussion is the essay \enquote{The Computational Case against Computational Literary Studies} by literary scholar Nan Z. Da. Her critique on the field of computational literary studies is divergent from other well-known comments, such as the claim that computational literary studies try to eliminate all close reading from literary studies\autocite[109]{north_literary_2017}, that distant reading is neoliberalism \textit{pur sang}\autocite{allington_neoliberal_nodate}, or that numbers are reducing reading to visualization.\autocite{underwood_it_2017} Instead, Da states that there is a \enquote{fundamental mismatch between the statistical tools that are used and the objects to which they are applied}.\autocite[601]{da_computational_2019} By rerunning several prominent studies, Da points at weaknesses in either their methodology, analysis or interpretation of results.

According to Da, all things that appear in computational literary studies \enquote{-- network analysis, digital mapping, linear and nonlinear regressions, topic modeling, topology, entropy -- are just fancier ways of talking about word frequency changes}.\autocite[607]{da_computational_2019} She notes that computational literary criticism places itself in a position of making claims based purely on word frequencies without regard to position, syntax, context, and semantics. In such way, it is prone to fallacious overclaims or misinterpretations of statistical results.\autocite[611]{da_computational_2019} This relates to the important distinction between the processing and visualization of data on the one hand and the interpretations and readings in their own right on the other hand, a difference which is often not made. To believe that these are the same thing is, according to Da,
\begin{quote}
	to mistake basic data work that may or may not lead up to a good interpretation and the interpretive choices that \textit{must be made} in any data work (or have no data work at all) for literary interpretation itself.\autocite[606]{da_computational_2019}
\end{quote}

\noindent In computational literary studies, word frequencies are asked to stand in for vastly different things, Da states. To define changes in word frequency as \textit{change} itself is both tautological and risky.\autocite[614]{da_computational_2019} However, in his reaction on Da's article (a post titled \enquote{Dear Humanists: Fear Not the Digital Revolution} in \textit{The Chronicle of Higher Education}), Underwood shows that recent publications go far beyond graphing the frequencies of words: \enquote{Sociologists have theorized the function of ambiguity in literary criticism; cognitive scientists have used information theory to describe historical change; the economist Thomas Piketty [has been] reinterpreting the last two centuries of history with illustrations drawn from Balzac.} \autocite{underwood_dear_2019} The above mentioned publications are the result of interdisciplinary teams with an interest in the humanities. Yet, the soothing title of Underwood's piece suggests that humanists should not be afraid the questions that historians and literary critics used to debate are completely scooped up by quantitative disciplines: there is an equal number of projects entirely led by humanists in the fields of digital humanities. And again, these projects are not merely about word frequencies. Underwood mentions a comparative study of Laura McGrath on titles used in publishing, in which she suggests that non-white writers are systematically pressured to compare themselves to white models. Another example mentioned is a study of Eve Kraicer and Andrew Piper, who studied millions of interactions between characters to show that contemporary fiction is still shaped by heteronormative patterns.\autocite{underwood_dear_2019}

Da's argument that all computational literary studies do nothing more than making claims based on word frequencies, therefore seems rather blunt. However, it would be unwise and incorrect to put away Da's critiques as irrelevant nonsense. Computational methods in literary studies are in fact laborious. Many improvements have to be made. Researchers need to remain or become critical on their methods. At the same time, humanities scholars should not be afraid to embrace quantitative methods in their research, because it will never replace the traditional methods, only add a new perspective. In that light I see this thesis: it introduces a very promising discipline, but at the same time it shows how complex computational methods can be, especially when applied to a corpus of historical texts. Da concludes with the bold statement that using computation in literary studies \enquote{takes nearly as much, if not far more, time and arbitrariness (and with much higher chance of meaninglessness and error) than actually reading them}.\autocite[638]{da_computational_2019} I dare to state that reading 43,772 songs in historical Dutch will take much more time and will provide fewer insights than taking a risk and actually finding out which role computational methods can play in order to get a grip on Dutch historical song culture and the dynamics within it.

\section{Extracting themes from a corpus}
To get an impression of the themes that were dominant in early modern Dutch songs, I could investigate which words are most frequently mentioned in the corpus. Imagine that, over all, the word \enquote{liefde} [love] has the highest number of appearances in the corpus. It is hard to make sense of that result: are these songs on a \enquote{love} towards another human being (a man, a woman, a mother, a son)? Or are they about \enquote{love} in a religious context, the love towards God? Or should we read it in a more political way and does \enquote{love} refer to a country, maybe a political leader? Clearly, just the appearance of a word is not enough to say something about topics of frequent occurrence in a corpus, since it does not take into account the multiple meanings a word can have. The meaning of a word can be found in the context, hence an improvement would be to look at the collocates: which words precede and follow the word \enquote{love}? The problem with collocates is that their interpretative value is limited: the meaning of a word might become clear when taking the three preceding and three following words into account, but it does not have to be that obvious. Moreover, themes are not based on the meaning of one frequently mentioned word and its collocates, but they are formed of a collection of words. Therefore, word-to-word-collocations do not provide enough information to rise to the level of a theme.\autocite[122]{jockers_macroanalysis_2013}

Topic modeling provides a solution to this. It is a way of extrapolating backward from a collection of documents to infer the discourses that could have generated them. Assumed is that each document in a collection of documents is constructed from a mix of some set of possible topics. A topic can be understood as a collection of words that have different probabilities of appearance in passages discussing the topic. The model assigns high probabilities to words and sets of words that tend to co-occur in multiple contexts across the corpus. Unlike collocates lists, that require careful human interrogation in order to parse out one word meaning from another, topic modeling is an unsupervised method. The model makes a wager that patterns in the data are sufficiently strong that different latent classes of observations will make themselves \enquote{visible}.\autocite[267]{karsdorp_humanities_2019} In this context it means that the algorithm does not know in advance what kind of texts are imported and what themes it has to look for. The algorithm infers information about individual word meanings based on their repeated appearance in similar contextual situation. The only human intervention required in the process, is setting the number of topics the algorithm has to discover. \autocites[123-124]{jockers_macroanalysis_2013}{underwood_topic_2012}

One of Da's other arguments against the computational literary studies is that, when taking word frequency counting as method, position, syntax and context of the words are not taken into account.\autocite[611]{da_computational_2019} This argument can be countered as well, using topic modeling as example. In conventional topic models (such as LDA), statistical techniques are employed to identify the underlying topic distribution, based on the high-order word co-occurence patterns. In that sense, position and syntax are not taken into account. However, these conventional models experience a performance degradation over short texts because of limited word co-occurrence information in short texts. As a solution, topic models with word embeddings were introduced. With word embeddings, words are represented as fixed-length vectors or embeddings. The goal of word embeddings is to capture semantic and syntactic regularities in language from large unsupervised sets of documents. Words that occur in the same context are represented by vectors in close proximity to each other. One example is a study of Chenliang Li et al., who introduce the GPU-DMM model, based on the Dirichlet Multinomial Mixture (DMM) model. This is designed to leverage the general word semantic relatedness knowledge during the topic inference process, to tackle the data sparsity issue.\autocite[166]{li_topic_2016} Li et al. showed, using two real-word short text corpora, that their GPU-DMM model outperforms existing state-of-the-art alternatives in terms of effectiveness and efficiency.\autocite[173]{li_topic_2016} Although in the context of their study the model with auxiliary word embeddings gave better results, it is not proven that topic models without word embeddings deliver poor and unreliable results. This shows that Da's statement about topic models not taking context into account, is an underestimation of the method.

Manually setting the number of topics the algorithm has to search for, is another majorly criticized part of the method. According to Da, topic modeling
\begin{quote}
	is extremely sensitive to parametricization, prone to overfitting, and is fairly unstable as an \enquote*{aboutness} finder for sophisticated texts because you need only tweak small details to discover completely different topics.\autocite[625]{da_computational_2019}
\end{quote}
Not only non-users are skeptical about the method; professional users have critically evaluated their methods as well. Jockers confirms that there is no consensus nor conventional wisdom regarding a perfect number of topics to extract. The parameter determining the number of topics to be harvested is largely dependent upon and determined by the scope and diversity of the corpus. He explains that
\begin{quote}
	[s]etting the number of topics too high may result in topics lacking enough contextual markers to provide a clear sense of how the topic is being expressed in the text; setting the number too low may result in topics of such a general nature that they tend to occur throughout the entire corpus.\autocite[128]{jockers_macroanalysis_2013}
\end{quote}
This shows that creating topic models is a precarious business. It needs to be implemented in a methodology in which is room for critical evaluation. In Chapter 7, I will explain how I will apply the topic modeling method in a fruitful way that allows me to critically evaluate it at the same time.